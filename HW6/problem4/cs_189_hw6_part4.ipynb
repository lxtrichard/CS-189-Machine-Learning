{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs 189 hw6 part4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQgANHt5MS2",
        "colab_type": "code",
        "outputId": "3b98eecd-4eb1-4ba7-cafe-d8888e9c9b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd /content/drive/My Drive/DL/CS 189/hw6/resources/problem4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DL/CS 189/hw6/resources/problem4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bTAHWs7RYi2",
        "colab_type": "code",
        "outputId": "fa1fa2ae-2e19-47c7-c0dc-e8d8c7bdac08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "pip install ipdb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.0.0)\n",
            "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UNSNexO7R4F",
        "colab_type": "text"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU1eGGfP7Uuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "\n",
        "class Mds189(data.Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, label_file, loader, transform):\n",
        "        'Initialization'\n",
        "        self.label_file = label_file\n",
        "        self.loader = loader\n",
        "        self.transform = transform\n",
        "        self.label_map = ['reach','squat','pushup','inline',\n",
        "                          'hamstrings','lunge','deadbug','stretch']\n",
        "        self.data= pd.read_csv(self.label_file,header=None)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.data)\n",
        "\n",
        "    def map_label_to_int(self,y):\n",
        "        'The labels need to be integers'\n",
        "        label_map = {'reach_both': 0,        # the key frames are labeled with the side\n",
        "                     'squat_both': 1,\n",
        "                     'inline_left': 2,\n",
        "                     'inline_right': 2,\n",
        "                     'lunge_left': 3,\n",
        "                     'lunge_right': 3,\n",
        "                     'hamstrings_left': 4,\n",
        "                     'hamstrings_right': 4,\n",
        "                     'stretch_left': 5,\n",
        "                     'stretch_right': 5,\n",
        "                     'deadbug_left': 6,\n",
        "                     'deadbug_right': 6,\n",
        "                     'pushup_both': 7,\n",
        "                     'reach': 0,            # the video frames don't have information about which side is moving \n",
        "                     'squat': 1,\n",
        "                     'inline': 2,\n",
        "                     'lunge': 3,\n",
        "                     'hamstrings': 4,\n",
        "                     'stretch': 5,\n",
        "                     'deadbug': 6,\n",
        "                     'pushup': 7,\n",
        "                     'label': -1           # label is the placeholder in `videoframe_data_test.txt` for the kaggle frame labels\n",
        "                    }\n",
        "        return label_map[y]\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        'Generates one sample of data'\n",
        "        path,target = self.data.iloc[idx]\n",
        "        sample = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        movement = self.map_label_to_int(target)\n",
        "\n",
        "        return sample,movement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLDqwgPC7l2J",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X24AVFs7RgFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import ipdb\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "start = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odoEJQHMRyQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions for loading images.\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlZNrwW5R7lm",
        "colab_type": "text"
      },
      "source": [
        "Network structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsaEP9XGR-Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,8,11,4)\n",
        "        self.mp1 = nn.MaxPool2d(5, 2)\n",
        "        self.conv2 = nn.Conv2d(8,16,5,1,2)\n",
        "        self.mp2 = nn.MaxPool2d(5, 2)\n",
        "        self.conv3 = nn.Conv2d(16,32,3,1,1)\n",
        "        self.conv4 = nn.Conv2d(32,64,3,1,1)\n",
        "        self.mp3 = nn.MaxPool2d(5, 2)        \n",
        "        self.fc1 = nn.Linear(2816, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 1024)\n",
        "        self.fc3 = nn.Linear(1024,8)\n",
        "        nn.init.xavier_normal_(self.conv1.weight)\n",
        "        nn.init.xavier_normal_(self.conv2.weight)\n",
        "        nn.init.xavier_normal_(self.conv3.weight)\n",
        "        nn.init.xavier_normal_(self.conv4.weight)\n",
        "        nn.init.xavier_normal_(self.fc1.weight)\n",
        "        nn.init.xavier_normal_(self.fc2.weight)\n",
        "        nn.init.xavier_normal_(self.fc3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.rrelu(self.mp1(self.conv1(x)))\n",
        "        x = F.rrelu(self.mp2(self.conv2(x)))\n",
        "        x = self.mp3(self.conv4(self.conv3(x)))\n",
        "        x = x.view(int(x.size(0)), -1)\n",
        "        x = F.dropout(F.rrelu(self.fc1(x)))\n",
        "        x = F.rrelu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOo9t1aJRzvN",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2YtBwmQR1gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mds_loader(params, is_key_frame=True):\n",
        "    # Datasets\n",
        "    # TODO: put the path to your train, test, validation txt files\n",
        "    if is_key_frame:\n",
        "        label_file_train =  'dataloader_files/keyframe_data_train.txt'\n",
        "        label_file_val  =  'dataloader_files/keyframe_data_val.txt'\n",
        "    else:\n",
        "        label_file_train = 'dataloader_files/videoframe_data_train.txt'\n",
        "        label_file_val = 'dataloader_files/videoframe_data_val.txt'\n",
        "        label_file_test = 'dataloader_files/videoframe_data_test.txt'\n",
        "\n",
        "    mean_keytrain = [134.010302198,118.599587912,102.038804945]\n",
        "    std_keytrain = [23.5033438916,23.8827343458,24.5498666589]\n",
        "    mean_randtrain = [133.714058398,118.396875912,102.262895484]\n",
        "    std_randtrain = [23.2021839891,23.7064439547,24.3690056102]\n",
        "\n",
        "    train_dataset = Mds189(label_file_train,loader=default_loader,transform=transforms.Compose([\n",
        "                                                transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "                                                transforms.RandomHorizontalFlip(p=0.33),\n",
        "                                                transforms.RandomRotation(degrees=15),    \n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean_keytrain, std_keytrain)\n",
        "                                            ]))\n",
        "    train_loader = data.DataLoader(train_dataset, **params)\n",
        "\n",
        "    val_dataset = Mds189(label_file_val,loader=default_loader,transform=transforms.Compose([\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean_randtrain, std_randtrain)\n",
        "                                            ]))\n",
        "    val_loader = data.DataLoader(val_dataset, **params)\n",
        "\n",
        "    if is_key_frame:\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    elif not is_key_frame:\n",
        "        test_dataset = Mds189(label_file_test,loader=default_loader,transform=transforms.Compose([\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean_randtrain, std_randtrain)\n",
        "                                                ]))\n",
        "        test_loader = data.DataLoader(test_dataset, **params)\n",
        "        return train_loader, val_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlH51cBXSDEE",
        "colab_type": "text"
      },
      "source": [
        "Trainning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeB647N4R5DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    # Train the model\n",
        "    # Loop over epochs\n",
        "    print('Beginning training..')\n",
        "    total_step = len(train_loader)\n",
        "    train_losses, val_losses = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        print('epoch {}'.format(epoch))\n",
        "        for i, (local_batch,local_labels) in enumerate(train_loader):\n",
        "            print(i)\n",
        "            # Transfer to GPU\n",
        "            local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model.forward(local_ims)\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            if (i+1) % 4 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "        for i, (local_batch,local_labels) in enumerate(val_loader):\n",
        "            local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "            outputs = model.forward(local_ims)\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            val_losses.append(loss.item())\n",
        "        print('finished epoch {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'\n",
        "                .format(epoch+1, train_losses[epoch], val_losses[epoch]))\n",
        "\n",
        "    end = time.time()\n",
        "    print('Time: {}'.format(end - start))\n",
        "\n",
        "    # Save the model checkpoint\n",
        "    torch.save(model.state_dict(), './model/model.ckpt')\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqO_kAN2SFAg",
        "colab_type": "text"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzW0FinuSIOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    print('Beginning Testing..')\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        predicted_list = []\n",
        "        groundtruth_list = []\n",
        "        for (local_batch,local_labels) in test_loader:\n",
        "            # Transfer to GPU\n",
        "            local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "\n",
        "            outputs = model.forward(local_ims)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += local_labels.size(0)\n",
        "            predicted_list.extend(predicted)\n",
        "            groundtruth_list.extend(local_labels)\n",
        "            correct += (predicted == local_labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "\n",
        "    pl = [p.cpu().numpy().tolist() for p in predicted_list]\n",
        "    gt = [p.cpu().numpy().tolist() for p in groundtruth_list]\n",
        "\n",
        "\n",
        "    label_map = ['reach','squat','inline','lunge','hamstrings','stretch','deadbug','pushup']\n",
        "    for id in range(len(label_map)):\n",
        "        print('{}: {}'.format(label_map[id],sum([p and g for (p,g) in zip(np.array(pl)==np.array(gt),np.array(gt)==id)])/(sum(np.array(gt)==id)+0.)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4JVEmtlSM_V",
        "colab_type": "text"
      },
      "source": [
        "Plot loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3s9V_mSSOgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(train,val):\n",
        "    mt = sum(train)/len(train)\n",
        "    mv = sum(val)/len(val)\n",
        "    plt.title(\" Avg Train Loss: \"+str(round(mt,4))+\", Avg Val Loss: \"+str(round(mv,4)))\n",
        "    plt.plot([i+1 for i in range(len(train))], train, 'r', label=\"train\")\n",
        "    plt.plot([i+1 for i in range(len(val))], val, 'b', label=\"validation\")\n",
        "    plt.xlabel(\"steps\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"loss.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_24Lt5zASQQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(params, num_epochs, learning_rate, is_train=True, is_key_frame=True):\n",
        "    \n",
        "    model_to_load = './model/model.ckpt' \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "    if is_key_frame:\n",
        "        train_loader, val_loader = mds_loader(params, is_key_frame=is_key_frame)\n",
        "    if not is_key_frame:\n",
        "        train_loader, val_loader, test_loader = mds_loader(params, is_key_frame=is_key_frame)\n",
        "\n",
        "    model = NeuralNet().to(device)\n",
        "\n",
        "    if is_train:\n",
        "        # Loss and optimizer\n",
        "        criterion = nn.CrossEntropyLoss() \n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        train_losses, val_losses = train(model, device, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
        "        plot_loss(train_losses, val_losses)\n",
        "    if not is_train:\n",
        "        num_epochs = 0\n",
        "        model.load_state_dict(torch.load(model_to_load))\n",
        "        test(model, device, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-lUqCESR6s",
        "colab_type": "code",
        "outputId": "557759d4-d7ea-4091-bb38-3bc5ee746c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "is_train=True\n",
        "is_key_frame=True\n",
        "params = {'batch_size': 64,\n",
        "      'shuffle': True,\n",
        "      'num_workers': 1\n",
        "      }\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "main(params, num_epochs, learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training..\n",
            "epoch 0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "Epoch [1/10], Step [4/46], Loss: 3.0813\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}